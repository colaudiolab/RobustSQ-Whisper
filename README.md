# RobustSQ-Whisper

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)
[![Python 3.9+](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.5+-red.svg)](https://pytorch.org/)

This is the official repository for the paper **"Attentive Statistics Pooling and Margin-Based Contrastive Learning for Target-Speaker ASR with Overlapped Enrollment"** submitted to **ICASSP 2026**.

## ğŸ“‹ Abstract

**RobustSQ-Whisper** is a lightweight, plug-in adaptation of **SQ-Whisper** for **target-speaker ASR (TS-ASR)** under **overlapped/noisy enrollment**. It strengthens the enrollment branch with:

## ğŸš€ Key Features

- **Attentive Statistics Pooling (ASP)** â€” query-conditioned, frame-weighted mean and standard deviation to suppress interference and model uncertainty.
- **Margin-based objectives** â€” **Arc-InfoNCE** (pairwise angular margin) and a **parallel AAM-Softmax** head (class-center angular margin) that enlarge inter-class separation and tighten intra-class variance.

> **No backbone changes.** **No extra inference-time cost.** No separators or external speaker models required.

## ğŸ—ï¸ Architecture

Our framework includes the following components for robust TS-ASR:

1. **ASP**: Attentive Statistics Pooling for speaker-aware sequence summarization
2. **SQ-Former**: Query-style conditioning to inject target speaker cues
3. **AAM-Softmax**: Angular margin classification head improving inter-/intra-class geometry
4. **Arc-InfoNCE**: Contrastive objective with angular margin against interferers and hard negatives

## ğŸ“Š Supported Backbones

| Category    | Backbone                     | Notes                                                |
| ----------- | ---------------------------- | ---------------------------------------------------- |
| **Whisper** | tiny / base / small / medium | Encoder-decoder backbone used by our TS-ASR pipeline |

## ğŸ“ Repository Structure

 This recipe follows ESPnetâ€™s `egs2/librimix` style. The tree below mirrors the main folders and scripts for TS-Whisper.

```
tgt_asr1/
â”œâ”€â”€ run_tswhisper.sh                    # Main TS-Whisper pipeline (train/decode)
â”œâ”€â”€ asr_my.sh                           # Custom ASR baseline/ablation script
â”œâ”€â”€ check_training_status.sh            # Monitor training/decoding status
â”œâ”€â”€ cmd.sh                              # Command launcher settings (local/queue)
â”œâ”€â”€ db.sh                               # Dataset paths (LibriSpeech/WHAM/Libri2Mix)
â”œâ”€â”€ path.sh                             # Environment setup
â”œâ”€â”€ gradscaler_fix.py                   # AMP/GradScaler patch (if needed)
â”œâ”€â”€ conf/
â”‚   â”œâ”€â”€ fbank.conf                      # Feature configs
â”‚   â”œâ”€â”€ pitch.conf
â”‚   â”œâ”€â”€ queue.conf / pbs.conf / slurm.conf
â”‚   â””â”€â”€ tswhisper/
â”‚       â”œâ”€â”€ train_tsasr_whisper_medium_full_con20_q16_l2_crop10_lr5e-5.yaml    #Train config
â”‚       â”œâ”€â”€ decode_asr_whisper_beam1.yaml
â”‚       â”œâ”€â”€ train_tsasr_whisper_medium_lora_qkvo_r16_.yaml
â”‚       â””â”€â”€ train_tsasr_whisper_medium_masking_.yaml
â”œâ”€â”€ datapre/
â”‚   â”œâ”€â”€ data_prep.sh                    # Bootstrap manifests/folders
â”‚   â”œâ”€â”€ data.sh
â”‚   â”œâ”€â”€ format_sglspk_dataset.py        # Build single-speaker lists
â”‚   â”œâ”€â”€ create_enrollment_.py           # Enrollment list creation
â”‚   â”œâ”€â”€ create_overlap_.py              # Overlap mixing (SIR)
â”‚   â””â”€â”€ add_wham_noise.py               # Add WHAM! noise (SNR)
â”œâ”€â”€ dump/
â”‚   â”œâ”€â”€ raw/{train,dev,test}_sglspk/    # Raw manifests
â”‚   â””â”€â”€ {train,dev,test}_sglspk/        # Standardized Kaldi/ESPnet files:
â”‚       â”œâ”€â”€ wav.scp  text  utt2spk  spk2utt
â”‚       â”œâ”€â”€ enroll.scp  resnet.scp (optional)
â”‚       â””â”€â”€ feats_type  utt2num_samples
â”œâ”€â”€ embedding/                          # Offline speaker embeddings
â”œâ”€â”€ pretrain_model/
â”‚   â”œâ”€â”€ voxceleb_resnet34_LM.onnx       # Speaker embedding model (optional)
â”‚   â””â”€â”€ whisper/                        # Whisper weights
â”œâ”€â”€ exp/                                # Experiments, logs, checkpoints
â”œâ”€â”€ parallel/                           # pbs.pl / slurm.pl / run.pl / retry.pl
â”œâ”€â”€ steps/                              # Kaldi-style helper steps
â””â”€â”€ utils/                              # Data utilities (combine/filter/split/etc.)
```

## ğŸ“š Datasets

We evaluate on mixtures derived from **LibriSpeech** with **WHAM!** noise via **Libri2Mix**.  
Please follow original licenses when downloading and using datasets.

- **Libri2Mix**: https://github.com/JorisCos/LibriMix  
- **LibriSpeech**: https://www.openslr.org/12  
- **WHAM!**: https://wham.whisper.ai/

## ğŸš§ Status

**âš ï¸ Code and configuration are being curated for camera-ready release. Full training/evaluation scripts and all configs will be provided after acceptance.**

## ğŸ™ Acknowledgments

We thank the following open-source projects and prior works:

- **ESPnet** â€” End-to-end speech processing toolkit  
- **Libri2Mix / LibriSpeech / WHAM!** â€” Datasets used in our experiments  
- Community implementations of **AAM-Softmax**, **InfoNCE/ArcFace-style** losses, and **Attentive Statistics Pooling**

## ğŸ“„ License

This project is licensed under the **MIT License** â€” see [LICENSE](LICENSE) for details.  
Datasets and pretrained models follow their respective licenses.

## ğŸ“ Contact

For questions and inquiries, please contact **[scyang]** at **scyang0108@163.com**.

---

**Note**: This repository is under active development. Please check back for updates after **ICASSP 2026** acceptance.

